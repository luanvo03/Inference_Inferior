{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch import LightningModule\n",
    "from typing import Optional, Any\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import MeanMetric\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMREAD\n",
    "def im2double(im):\n",
    "  \"\"\" Converts an uint image to floating-point format [0-1].\n",
    "\n",
    "  Args:\n",
    "    im: image (uint ndarray); supported input formats are: uint8 or uint16.\n",
    "\n",
    "  Returns:\n",
    "    input image in floating-point format [0-1].\n",
    "  \"\"\"\n",
    "\n",
    "  if im[0].dtype == 'uint8' or im[0].dtype == 'int16':\n",
    "    max_value = 255\n",
    "  elif im[0].dtype == 'uint16' or im[0].dtype == 'int32':\n",
    "    max_value = 65535\n",
    "  return im.astype('float') / max_value\n",
    "\n",
    "def imread(file, gray=False):\n",
    "  image = Image.open(file)\n",
    "  image = np.array(image)\n",
    "  if not gray:\n",
    "    image = image[:, :, :3]\n",
    "  image = im2double(image)\n",
    "  return image\n",
    "\n",
    "# IMRESIZE\n",
    "def cubic(x):\n",
    "    x = np.array(x).astype(np.float64)\n",
    "    absx = np.absolute(x)\n",
    "    absx2 = np.multiply(absx, absx)\n",
    "    absx3 = np.multiply(absx2, absx)\n",
    "    f = np.multiply(1.5*absx3 - 2.5*absx2 + 1, absx <= 1) + np.multiply(-0.5*absx3 + 2.5*absx2 - 4*absx + 2, (1 < absx) & (absx <= 2))\n",
    "    return f\n",
    "\n",
    "def deriveSizeFromScale(img_shape, scale):\n",
    "    output_shape = []\n",
    "    for k in range(2):\n",
    "        output_shape.append(int(ceil(scale[k] * img_shape[k])))\n",
    "    return output_shape\n",
    "\n",
    "def deriveScaleFromSize(img_shape_in, img_shape_out):\n",
    "    scale = []\n",
    "    for k in range(2):\n",
    "        scale.append(1.0 * img_shape_out[k] / img_shape_in[k])\n",
    "    return scale\n",
    "\n",
    "def contributions(in_length, out_length, scale, kernel, k_width):\n",
    "    if scale < 1:\n",
    "        h = lambda x: scale * kernel(scale * x)\n",
    "        kernel_width = 1.0 * k_width / scale\n",
    "    else:\n",
    "        h = kernel\n",
    "        kernel_width = k_width\n",
    "    x = np.arange(1, out_length+1).astype(np.float64)\n",
    "    u = x / scale + 0.5 * (1 - 1 / scale)\n",
    "    left = np.floor(u - kernel_width / 2)\n",
    "    P = int(ceil(kernel_width)) + 2\n",
    "    ind = np.expand_dims(left, axis=1) + np.arange(P) - 1 # -1 because indexing from 0\n",
    "    indices = ind.astype(np.int32)\n",
    "    weights = h(np.expand_dims(u, axis=1) - indices - 1) # -1 because indexing from 0\n",
    "    weights = np.divide(weights, np.expand_dims(np.sum(weights, axis=1), axis=1))\n",
    "    aux = np.concatenate((np.arange(in_length), np.arange(in_length - 1, -1, step=-1))).astype(np.int32)\n",
    "    indices = aux[np.mod(indices, aux.size)]\n",
    "    ind2store = np.nonzero(np.any(weights, axis=0))\n",
    "    weights = weights[:, ind2store]\n",
    "    indices = indices[:, ind2store]\n",
    "    return weights, indices\n",
    "\n",
    "def resizeAlongDim(A, dim, weights, indices, mode=\"vec\"):\n",
    "    if mode == \"org\":\n",
    "        out = imresizemex(A, weights, indices, dim)\n",
    "    else:\n",
    "        out = imresizevec(A, weights, indices, dim)\n",
    "    return out\n",
    "\n",
    "def imresizemex(inimg, weights, indices, dim):\n",
    "    in_shape = inimg.shape\n",
    "    w_shape = weights.shape\n",
    "    out_shape = list(in_shape)\n",
    "    out_shape[dim] = w_shape[0]\n",
    "    outimg = np.zeros(out_shape)\n",
    "    if dim == 0:\n",
    "        for i_img in range(in_shape[1]):\n",
    "            for i_w in range(w_shape[0]):\n",
    "                w = weights[i_w, :]\n",
    "                ind = indices[i_w, :]\n",
    "                im_slice = inimg[ind, i_img].astype(np.float64)\n",
    "                outimg[i_w, i_img] = np.sum(np.multiply(np.squeeze(im_slice, axis=0), w.T), axis=0)\n",
    "    elif dim == 1:\n",
    "        for i_img in range(in_shape[0]):\n",
    "            for i_w in range(w_shape[0]):\n",
    "                w = weights[i_w, :]\n",
    "                ind = indices[i_w, :]\n",
    "                im_slice = inimg[i_img, ind].astype(np.float64)\n",
    "                outimg[i_img, i_w] = np.sum(np.multiply(np.squeeze(im_slice, axis=0), w.T), axis=0)        \n",
    "    if inimg.dtype == np.uint8:\n",
    "        outimg = np.clip(outimg, 0, 255)\n",
    "        return np.around(outimg).astype(np.uint8)\n",
    "    else:\n",
    "        return outimg\n",
    "    \n",
    "def imresizevec(inimg, weights, indices, dim):\n",
    "    wshape = weights.shape\n",
    "    if dim == 0:\n",
    "        weights = weights.reshape((wshape[0], wshape[2], 1, 1))\n",
    "        outimg =  np.sum(weights*((inimg[indices].squeeze(axis=1)).astype(np.float64)), axis=1)\n",
    "    elif dim == 1:\n",
    "        weights = weights.reshape((1, wshape[0], wshape[2], 1))\n",
    "        outimg =  np.sum(weights*((inimg[:, indices].squeeze(axis=2)).astype(np.float64)), axis=2)\n",
    "    if inimg.dtype == np.uint8:\n",
    "        outimg = np.clip(outimg, 0, 255)\n",
    "        return np.around(outimg).astype(np.uint8)\n",
    "    else:\n",
    "        return outimg\n",
    "\n",
    "def imresize(I, scalar_scale=None, method='bicubic', output_shape=None, mode=\"vec\"):\n",
    "    if method == 'bicubic':\n",
    "        kernel = cubic\n",
    "    else:\n",
    "        print ('Error: Unidentified method supplied')\n",
    "        \n",
    "    kernel_width = 4.0\n",
    "    # Fill scale and output_size\n",
    "    if scalar_scale is not None:\n",
    "        scalar_scale = float(scalar_scale)\n",
    "        scale = [scalar_scale, scalar_scale]\n",
    "        output_size = deriveSizeFromScale(I.shape, scale)\n",
    "    elif output_shape is not None:\n",
    "        scale = deriveScaleFromSize(I.shape, output_shape)\n",
    "        output_size = list(output_shape)\n",
    "    else:\n",
    "        print ('Error: scalar_scale OR output_shape should be defined!')\n",
    "        return\n",
    "    scale_np = np.array(scale)\n",
    "    order = np.argsort(scale_np)\n",
    "    weights = []\n",
    "    indices = []\n",
    "    for k in range(2):\n",
    "        w, ind = contributions(I.shape[k], output_size[k], scale[k], kernel, kernel_width)\n",
    "        weights.append(w)\n",
    "        indices.append(ind)\n",
    "    B = np.copy(I) \n",
    "    flag2D = False\n",
    "    if B.ndim == 2:\n",
    "        B = np.expand_dims(B, axis=2)\n",
    "        flag2D = True\n",
    "    for k in range(2):\n",
    "        dim = order[k]\n",
    "        B = resizeAlongDim(B, dim, weights[dim], indices[dim], mode)\n",
    "    if flag2D:\n",
    "        B = np.squeeze(B, axis=2)\n",
    "    return B\n",
    "  \n",
    "def batch_aug(image: np.array):\n",
    "  aug_op = np.random.randint(4)\n",
    "    \n",
    "  if aug_op == 1:\n",
    "    image = np.flipud(image)\n",
    "  elif aug_op == 2:\n",
    "    image = np.fliplr(image)\n",
    "  elif aug_op == 3:\n",
    "    scale = np.random.uniform(low=0.75, high=1.25)\n",
    "    \n",
    "    result = []\n",
    "    for i in range(image.shape[0]):\n",
    "      result.append(imresize(image[i,:], scalar_scale=scale))\n",
    "    image = np.stack(result, axis=0).squeeze()\n",
    "    \n",
    "  return image\n",
    "\n",
    "def batch_extract_path(image:np.array, patch_size:int=256, patch_number:int=8):\n",
    "  _, h, w, _ = image.shape\n",
    "  \n",
    "  for patch in range(patch_number):\n",
    "    patch_x = np.random.randint(0, high=w-patch_size)\n",
    "    patch_y = np.random.randint(0, high=h-patch_size)\n",
    "    \n",
    "    if patch == 0:\n",
    "      _patch = np.expand_dims(image[:,\n",
    "                     patch_y:patch_y + patch_size, \n",
    "                     patch_x:patch_x + patch_size, \n",
    "                     :], axis=0) # [patch, bz, w, h, c]\n",
    "    else:\n",
    "      _patch = np.concatenate((\n",
    "        _patch,\n",
    "        np.expand_dims(image[:,\n",
    "                             patch_y:patch_y + patch_size,\n",
    "                             patch_x:patch_x + patch_size,\n",
    "                             :], axis=0)),\n",
    "        axis=0\n",
    "      )\n",
    "      \n",
    "  return _patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridNet(nn.Module):\n",
    "  def __init__(self, inchnls=3, outchnls=3, initialchnls=16, rows=3,\n",
    "               columns=6, norm=False, device='cuda'):\n",
    "    \"\"\" GridNet constructor.\n",
    "\n",
    "    Args:\n",
    "      inchnls: input channels; default is 3.\n",
    "      outchnls: output channels; default is 3.\n",
    "      initialchnls: initial number of feature channels; default is 16.\n",
    "      rows: number of rows; default is 3.\n",
    "      columns: number of columns; default is 6 (should be an even number).\n",
    "      norm: apply batch norm as used in Ref. 1; default is False (i.e., Ref. 2)\n",
    "    \"\"\"\n",
    "\n",
    "    super(GridNet, self).__init__()\n",
    "    assert columns % 2 == 0, 'use even number of columns'\n",
    "    assert columns > 1, 'use number of columns > 1'\n",
    "    assert rows > 1, 'use number of rows > 1'\n",
    "\n",
    "    self.device = device\n",
    "    \n",
    "    self.encoder = nn.ModuleList([])\n",
    "    self.decoder = nn.ModuleList([])\n",
    "    self.rows = rows\n",
    "    self.columns = columns\n",
    "\n",
    "    # encoder\n",
    "    for r in range(rows):\n",
    "      res_blocks = nn.ModuleList([])\n",
    "      down_blocks = nn.ModuleList([])\n",
    "      for c in range(int(columns / 2)):\n",
    "        if r == 0:\n",
    "          if c == 0:\n",
    "            res_blocks.append(ForwardBlock(in_dim=inchnls,\n",
    "                                          out_dim=initialchnls,\n",
    "                                          norm=norm).to(device=self.device))\n",
    "          else:\n",
    "            res_blocks.append(ResidualBlock(in_dim=initialchnls, norm=norm).to(device=self.device))\n",
    "          down_blocks.append(SubsamplingBlock(\n",
    "            in_dim=initialchnls, norm=norm).to(device=self.device))\n",
    "        else:\n",
    "          if c > 0:\n",
    "            res_blocks.append(ResidualBlock(\n",
    "              in_dim=initialchnls * (2 ** r), norm=norm).to(device=self.device))\n",
    "          else:\n",
    "            res_blocks.append(nn.ModuleList([]))\n",
    "          if r < (rows - 1):\n",
    "            down_blocks.append(SubsamplingBlock(\n",
    "              in_dim=initialchnls * (2 ** r), norm=norm).to(device=self.device))\n",
    "          else:\n",
    "            down_blocks.append(nn.ModuleList([]))\n",
    "\n",
    "      self.encoder.append(res_blocks)\n",
    "      self.encoder.append(down_blocks)\n",
    "\n",
    "\n",
    "    # decoder\n",
    "    for r in range((rows - 1), -1, -1):\n",
    "      res_blocks = nn.ModuleList([])\n",
    "      up_blocks = nn.ModuleList([])\n",
    "      for c in range(int(columns / 2), columns):\n",
    "        if r == 0:\n",
    "          res_blocks.append(ResidualBlock(in_dim=initialchnls,\n",
    "                                          norm=norm).to(device=self.device))\n",
    "          up_blocks.append(nn.ModuleList([]))\n",
    "        elif r > 0:\n",
    "          res_blocks.append(ResidualBlock(\n",
    "              in_dim=initialchnls * (2 ** r), norm=norm).to(device=self.device))\n",
    "          up_blocks.append(UpsamplingBlock(\n",
    "            in_dim=initialchnls * (2 ** r), norm=norm).to(device=self.device))\n",
    "\n",
    "      self.decoder.append(res_blocks)\n",
    "      self.decoder.append(up_blocks)\n",
    "\n",
    "    self.output = ForwardBlock(in_dim=initialchnls, out_dim=outchnls,\n",
    "                                norm=norm).to(device=self.device)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\" Forward function\n",
    "\n",
    "    Args:\n",
    "      x: input image\n",
    "\n",
    "    Returns:\n",
    "      output: output image\n",
    "    \"\"\"\n",
    "    latent_downscaled = []\n",
    "    latent_upscaled = []\n",
    "    latent_forward = []\n",
    "\n",
    "    for i in range(0, len(self.encoder), 2):\n",
    "      res_blcks = self.encoder[i]\n",
    "      branch_blcks = self.encoder[i + 1]\n",
    "      if not branch_blcks[0]:\n",
    "        not_last = False\n",
    "      else:\n",
    "        not_last = True\n",
    "      for j, (res_blck, branch_blck) in enumerate(zip(res_blcks,\n",
    "                                                      branch_blcks)):\n",
    "        if i == 0 and j == 0:\n",
    "          x_latent = res_blck(x)\n",
    "        elif i == 0:\n",
    "          x_latent = res_blck(x_latent)\n",
    "        elif j == 0:\n",
    "          x_latent = latent_downscaled[j]\n",
    "        else:\n",
    "          x_latent = res_blck(x_latent)\n",
    "          x_latent = x_latent + latent_downscaled[j]\n",
    "        if i == 0:\n",
    "          latent_downscaled.append(branch_blck(x_latent))\n",
    "        elif not_last:\n",
    "          latent_downscaled[j] = branch_blck(x_latent)\n",
    "      latent_forward.append(x_latent)\n",
    "\n",
    "    latent_forward.reverse()\n",
    "\n",
    "    for k, i in enumerate(range(0, len(self.decoder), 2)):\n",
    "      res_blcks = self.decoder[i]\n",
    "      branch_blcks = self.decoder[i + 1]\n",
    "      if not branch_blcks[0]:\n",
    "        not_last = False\n",
    "      else:\n",
    "        not_last = True\n",
    "      for j, (res_blck, branch_blck) in enumerate(zip(res_blcks,\n",
    "                                                      branch_blcks)):\n",
    "        if j == 0:\n",
    "          latent_x = latent_forward[k]\n",
    "        x_latent = res_blck(latent_x)\n",
    "        if i > 0:\n",
    "          x_latent = x_latent + latent_upscaled[j]\n",
    "        if i == 0:\n",
    "          latent_upscaled.append(branch_blck(x_latent))\n",
    "        elif not_last:\n",
    "          latent_upscaled[j] = branch_blck(x_latent)\n",
    "\n",
    "    output = self.output(x_latent)\n",
    "    return output\n",
    "\n",
    "\n",
    "class SubsamplingBlock(nn.Module):\n",
    "  \"\"\" SubsamplingBlock\"\"\"\n",
    "\n",
    "  def __init__(self, in_dim, norm=False):\n",
    "    super(SubsamplingBlock, self).__init__()\n",
    "    self.output = None\n",
    "    if norm:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_dim),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, int(in_dim * 2), kernel_size=3, padding=1, stride=2),\n",
    "        nn.BatchNorm2d(int(in_dim * 2)),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(int(in_dim * 2), int(in_dim * 2), kernel_size=3, padding=1))\n",
    "    else:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, int(in_dim * 2), kernel_size=3, padding=1, stride=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(int(in_dim * 2), int(in_dim * 2), kernel_size=3, padding=1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.block(x)\n",
    "\n",
    "\n",
    "class UpsamplingBlock(nn.Module):\n",
    "  \"\"\" UpsamplingBlock\"\"\"\n",
    "\n",
    "  def __init__(self, in_dim, norm=False):\n",
    "    super(UpsamplingBlock, self).__init__()\n",
    "    self.output = None\n",
    "    if norm:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=True),\n",
    "        nn.BatchNorm2d(in_dim),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, int(in_dim / 2), kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(int(in_dim / 2)),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(int(in_dim / 2), int(in_dim / 2), kernel_size=3, padding=1))\n",
    "    else:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=True),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, int(in_dim / 2), kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(int(in_dim / 2), int(in_dim / 2), kernel_size=3, padding=1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.block(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "  \"\"\" ResidualBlock\"\"\"\n",
    "\n",
    "  def __init__(self, in_dim, out_dim=None, norm=False):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.output = None\n",
    "    intermediate_dim = int(in_dim * 2)\n",
    "    if out_dim is None:\n",
    "      out_dim = in_dim\n",
    "    if norm:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_dim),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, intermediate_dim, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(intermediate_dim),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(intermediate_dim, out_dim, kernel_size=3, padding=1))\n",
    "    else:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, intermediate_dim, kernel_size=3, padding=1),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(intermediate_dim, out_dim, kernel_size=3, padding=1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x + self.block(x)\n",
    "\n",
    "\n",
    "\n",
    "class ForwardBlock(nn.Module):\n",
    "  \"\"\" ForwardBlock\"\"\"\n",
    "\n",
    "  def __init__(self, in_dim, out_dim=None, norm=False):\n",
    "    super(ForwardBlock, self).__init__()\n",
    "    self.output = None\n",
    "    intermediate_dim = int(in_dim * 2)\n",
    "    if out_dim is None:\n",
    "      out_dim = in_dim\n",
    "    if norm:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.BatchNorm2d(in_dim),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, intermediate_dim, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(intermediate_dim),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(intermediate_dim, out_dim, kernel_size=3, padding=1))\n",
    "    else:\n",
    "      self.block = nn.Sequential(\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(in_dim, intermediate_dim, kernel_size=3, padding=1),\n",
    "        nn.PReLU(init=0.25),\n",
    "        nn.Conv2d(intermediate_dim, out_dim, kernel_size=3, padding=1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WBNet(nn.Module):\n",
    "  def __init__(self, inchnls=9, initialchnls=8, rows=4, columns=6,\n",
    "              norm=False, device='cuda'):\n",
    "    \"\"\" Network constructor.\n",
    "    \"\"\"\n",
    "    self.outchnls = int(inchnls/3)\n",
    "    self.inchnls = inchnls\n",
    "    self.device = device\n",
    "    super(WBNet, self).__init__()\n",
    "    assert columns % 2 == 0, 'use even number of columns'\n",
    "    assert columns > 1, 'use number of columns > 1'\n",
    "    assert rows > 1, 'use number of rows > 1'\n",
    "    self.net = GridNet(inchnls=self.inchnls, outchnls=self.outchnls,\n",
    "                      initialchnls=initialchnls, rows=rows, columns=columns,\n",
    "                      norm=norm, device=self.device)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\" Forward function\"\"\"\n",
    "    weights = self.net(x)\n",
    "    weights = torch.clamp(weights, -1000, 1000)\n",
    "    weights = self.softmax(weights)\n",
    "    out_img = torch.unsqueeze(weights[:, 0, :, :], dim=1) * x[:, :3, :, :]\n",
    "    for i in range(1, int(x.shape[1] // 3)):\n",
    "      out_img += torch.unsqueeze(weights[:, i, :, :],\n",
    "                                 dim=1) * x[:, (i * 3):3 + (i * 3), :, :]\n",
    "    return out_img, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sobel_kernel(chnls=5):\n",
    "  x_kernel = [[1, 0, -1], [2, 0, -2], [1, 0, -1]]\n",
    "  x_kernel = torch.tensor(x_kernel, dtype=torch.float32).unsqueeze(0).expand(\n",
    "    1, chnls, 3, 3)\n",
    "  x_kernel.requires_grad = False\n",
    "  y_kernel = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "  y_kernel = torch.tensor(y_kernel, dtype=torch.float32).unsqueeze(0).expand(\n",
    "    1, chnls, 3, 3)\n",
    "  y_kernel.requires_grad = False\n",
    "  return x_kernel, y_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAWB(LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        x_kernel,\n",
    "        y_kernel,\n",
    "        lr:float=0.01, \n",
    "        smooth_weight:int=1,\n",
    "        dist:bool=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.smooth_weight = smooth_weight\n",
    "        self.x_kernel = x_kernel\n",
    "        self.y_kernel = y_kernel\n",
    "        self.lr = lr\n",
    "        self.sync_dist = True if dist else False\n",
    "        self.mean_valid_loss = MeanMetric()\n",
    "\n",
    "        \n",
    "    def forward(self, x:torch.tensor):\n",
    "        logits = self.model(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch[0], batch[1]\n",
    "        rec_loss, smooth_loss = 0, 0\n",
    "        for c in range(inputs.shape[1]):\n",
    "            patch = inputs[:, c, :, :]\n",
    "            gt_patch = targets[:, c, :, :, :]\n",
    "            pred, pred_weights = self(patch)\n",
    "            \n",
    "            # calculate loss\n",
    "            rec_loss += F.mse_loss(pred, gt_patch)\n",
    "            \n",
    "            # smooth loss\n",
    "            smooth_loss += self.smooth_weight * (\n",
    "                torch.sum(F.conv2d(pred_weights, self.x_kernel.to(pred_weights.device))) + torch.sum(F.conv2d(pred_weights, self.y_kernel.to(pred_weights.device)))\n",
    "            )\n",
    "        \n",
    "        loss = (rec_loss / inputs.shape[0]) + (smooth_loss / inputs.shape[0])\n",
    "        \n",
    "        self.log(\"train/loss\", loss.item(), on_epoch=True, prog_bar=True, logger=True, sync_dist=self.sync_dist)        \n",
    "        self.log(\"train/rec_loss\", rec_loss.item(), on_epoch=True, prog_bar=True, logger=True, sync_dist=self.sync_dist)\n",
    "        self.log(\"train/smooth_loss\", smooth_loss.item(), on_epoch=True, prog_bar=True, logger=True, sync_dist=self.sync_dist)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch[0], batch[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred, _ = self(inputs[:, 0, :, :])\n",
    "            \n",
    "        val_loss = F.mse_loss(pred,  targets[:, 0, :, :, :])\n",
    "        \n",
    "        self.mean_valid_loss.update(val_loss, weight=inputs.shape[0])\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val/loss\", self.mean_valid_loss, prog_bar=True, sync_dist=self.sync_dist, logger=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        # self.hparams available because we called self.save_hyperparameters()\n",
    "        optimizer =  torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=5e-4)\n",
    "        \n",
    "        return [optimizer]\n",
    "\n",
    "    def save_checkpoint(self, filepath, weights_only:bool=False, storage_options:Optional[Any]=None) -> None:\n",
    "        checkpoint = self._checkpoint_connector.dump_checkpoint(weights_only)\n",
    "        self.strategy.save_checkpoint(checkpoint, filepath, storage_options=storage_options)\n",
    "        self.strategy.barrier(\"Trainer.save_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_size = 320\n",
    "patch_size = 64\n",
    "patch_number = 32\n",
    "wb_settings = [\"D\", \"S\", \"T\"]\n",
    "lr = 0.01\n",
    "smoothness_weight = 1\n",
    "testdir = \"datahub/cwcc_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitAWB(\n",
       "  (model): WBNet(\n",
       "    (net): GridNet(\n",
       "      (encoder): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ForwardBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(9, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(18, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1-2): 2 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-2): 3 x SubsamplingBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ModuleList()\n",
       "          (1-2): 2 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0-2): 3 x SubsamplingBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): ModuleList()\n",
       "          (1-2): 2 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0-2): 3 x SubsamplingBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ModuleList(\n",
       "          (0): ModuleList()\n",
       "          (1-2): 2 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ModuleList(\n",
       "          (0-2): 3 x ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (decoder): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0-2): 3 x UpsamplingBlock(\n",
       "            (block): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "              (1): PReLU(num_parameters=1)\n",
       "              (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): ReLU(inplace=True)\n",
       "              (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0-2): 3 x UpsamplingBlock(\n",
       "            (block): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "              (1): PReLU(num_parameters=1)\n",
       "              (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): ReLU(inplace=True)\n",
       "              (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0-2): 3 x UpsamplingBlock(\n",
       "            (block): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "              (1): PReLU(num_parameters=1)\n",
       "              (2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): ReLU(inplace=True)\n",
       "              (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "              (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (2): PReLU(num_parameters=1)\n",
       "              (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ModuleList(\n",
       "          (0-2): 3 x ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (output): ForwardBlock(\n",
       "        (block): Sequential(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "          (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): PReLU(num_parameters=1)\n",
       "          (3): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (mean_valid_loss): MeanMetric()\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = WBNet(device=device, inchnls=3 * len(wb_settings))\n",
    "x_kernel, y_kernel = get_sobel_kernel(chnls=len(wb_settings))\n",
    "litmodel = LitAWB(model=net, lr=lr, smooth_weight=smoothness_weight, x_kernel=x_kernel, y_kernel=y_kernel)\n",
    "model_path = \"checkpoints/sample-epoch=97.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "litmodel.load_state_dict(checkpoint[\"state_dict\"])\n",
    "litmodel.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(im, dims=3):\n",
    "  \"\"\" Converts a given ndarray image to torch tensor image.\n",
    "\n",
    "  Args:\n",
    "    im: ndarray image (height x width x channel x [sample]).\n",
    "    dims: dimension number of the given image. If dims = 3, the image should\n",
    "      be in (height x width x channel) format; while if dims = 4, the image\n",
    "      should be in (height x width x channel x sample) format; default is 3.\n",
    "\n",
    "  Returns:\n",
    "    torch tensor in the format (channel x height x width)  or (sample x\n",
    "      channel x height x width).\n",
    "  \"\"\"\n",
    "\n",
    "  assert (dims == 3 or dims == 4)\n",
    "  if dims == 3:\n",
    "    im = im.transpose((2, 0, 1))\n",
    "  elif dims == 4:\n",
    "    im = im.transpose((0, 3, 1, 2))\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return torch.from_numpy(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "torch.Size([1, 3, 1080, 1920])\n",
      "torch.Size([9, 313, 313])\n"
     ]
    }
   ],
   "source": [
    "index = 2304\n",
    "img1 = imread(f\"/home/tiennv/FPT/Inference_Inferior/imgs/{index}_1.png\")\n",
    "img2 = imread(f\"/home/tiennv/FPT/Inference_Inferior/imgs/{index}_2.png\")\n",
    "img3 = imread(f\"/home/tiennv/FPT/Inference_Inferior/imgs/{index}_3.png\")\n",
    "print(img1.shape)\n",
    "d_img = to_tensor(img1).unsqueeze(0).cuda(0)\n",
    "s_img = to_tensor(img2).unsqueeze(0).cuda(0)\n",
    "t_img = to_tensor(img3).unsqueeze(0).cuda(0)\n",
    "print(d_img.shape)\n",
    "\n",
    "img2 = imresize(img2, output_shape=(t_size, t_size))\n",
    "img1 = imresize(img1, output_shape=(t_size, t_size))\n",
    "img3 = imresize(img3, output_shape=(t_size, t_size))\n",
    "\n",
    "batched_imgs = np.stack([img1, img2, img3], axis=0).squeeze()\n",
    "batched_imgs = batch_aug(batched_imgs)\n",
    "# print(len(batched_imgs))\n",
    "inp_model = np.asarray(batched_imgs)\n",
    "# print(inp_model)\n",
    "inp_model = torch.as_tensor(inp_model)\n",
    "num_inp, w, h, c = inp_model.shape\n",
    "inp_model = inp_model.reshape(num_inp*c, w, h)\n",
    "print(inp_model.shape)\n",
    "imgs = [d_img, s_img, t_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (79) must match the size of tensor b (80) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m       img \u001b[38;5;241m=\u001b[39m inp_model\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m       _, weights \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m       \u001b[38;5;66;03m# print(weights.shape)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m       \u001b[38;5;66;03m# print(d_img.shape)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m       weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(\n\u001b[1;32m      7\u001b[0m         weights, size\u001b[38;5;241m=\u001b[39m(d_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], d_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]),\n\u001b[1;32m      8\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/cwcc/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cwcc/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 20\u001b[0m, in \u001b[0;36mWBNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\" Forward function\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m   weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m   weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(weights, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     22\u001b[0m   weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(weights)\n",
      "File \u001b[0;32m~/.conda/envs/cwcc/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cwcc/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[57], line 131\u001b[0m, in \u001b[0;36mGridNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m x_latent \u001b[38;5;241m=\u001b[39m res_blck(latent_x)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m   x_latent \u001b[38;5;241m=\u001b[39m \u001b[43mx_latent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlatent_upscaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    133\u001b[0m   latent_upscaled\u001b[38;5;241m.\u001b[39mappend(branch_blck(x_latent))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (79) must match the size of tensor b (80) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "      img = inp_model.to(device=device, dtype=torch.float32).unsqueeze(0)\n",
    "      _, weights = net(img)\n",
    "      # print(weights.shape)\n",
    "      # print(d_img.shape)\n",
    "      weights = F.interpolate(\n",
    "        weights, size=(d_img.shape[2], d_img.shape[3]),\n",
    "        mode='bilinear', align_corners=True)\n",
    "for i in range(weights.shape[1]):\n",
    "  if i == 0:\n",
    "    out_img = torch.unsqueeze(weights[:, i, :, :], dim=1) * imgs[i]\n",
    "  else:\n",
    "    out_img += torch.unsqueeze(weights[:, i, :, :], dim=1) * imgs[i] \n",
    "    \n",
    "def from_tensor_to_image(tensor):\n",
    "  \"\"\" Converts torch tensor image to numpy tensor image.\n",
    "\n",
    "  Args:\n",
    "    tensor: torch image tensor in one of the following formats:\n",
    "      - 1 x channel x height x width\n",
    "      - channel x height x width\n",
    "\n",
    "  Returns:\n",
    "    return a cpu numpy tensor image in one of the following formats:\n",
    "      - 1 x height x width x channel\n",
    "      - height x width x channel\n",
    "  \"\"\"\n",
    "\n",
    "  image = tensor.cpu().numpy()\n",
    "  if len(image.shape) == 4:\n",
    "    image = image.transpose(0, 2, 3, 1)\n",
    "  if len(image.shape) == 3:\n",
    "    image = image.transpose(1, 2, 0)\n",
    "  return image\n",
    "def to_image(image):\n",
    "    \"\"\" converts to PIL image \"\"\"\n",
    "    image = from_tensor_to_image(image)\n",
    "    return Image.fromarray((image * 255).astype(np.uint8))     \n",
    "result = to_image(out_img[0, :, :, :])\n",
    "result.save(os.path.join(\"imgs\", \"output.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
